{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport pandas\nfrom torch.utils.data import DataLoader,Dataset, random_split, Subset\nfrom matplotlib.pylab import plt\nimport warnings\n\nfrom torchmetrics.classification import BinaryAccuracy\nimport os\nimport shutil\n# torch.manual_seed(5)\n\n\nwarnings.filterwarnings('ignore')\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:18.889678Z","iopub.execute_input":"2023-06-03T10:28:18.890129Z","iopub.status.idle":"2023-06-03T10:28:33.306788Z","shell.execute_reply.started":"2023-06-03T10:28:18.890078Z","shell.execute_reply":"2023-06-03T10:28:33.305631Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"class EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, trace_func=print):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            trace_func (function): trace print function.\n                            Default: print            \n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.trace_func = trace_func\n        \n    def __call__(self, val_loss, model, path):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model, path)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model, path)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model, path):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), path)\n        self.val_loss_min = val_loss","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:33.309142Z","iopub.execute_input":"2023-06-03T10:28:33.309519Z","iopub.status.idle":"2023-06-03T10:28:33.322294Z","shell.execute_reply.started":"2023-06-03T10:28:33.309485Z","shell.execute_reply":"2023-06-03T10:28:33.321297Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"important_dirs = [\"Weights\",\"Weights/FPC\",\"Weights/Scenario1\",\"Weights/Scenario2\"]\n\nfor dir in important_dirs:\n    if(os.path.isdir(dir)==False):\n        print(\"Creating Directory :\", dir)\n        os.mkdir(dir)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:33.323776Z","iopub.execute_input":"2023-06-03T10:28:33.324636Z","iopub.status.idle":"2023-06-03T10:28:33.338148Z","shell.execute_reply.started":"2023-06-03T10:28:33.324495Z","shell.execute_reply":"2023-06-03T10:28:33.337050Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Creating Directory : Weights\nCreating Directory : Weights/FPC\nCreating Directory : Weights/Scenario1\nCreating Directory : Weights/Scenario2\n","output_type":"stream"}]},{"cell_type":"code","source":"# from torchview import draw_graph","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:33.339880Z","iopub.execute_input":"2023-06-03T10:28:33.340787Z","iopub.status.idle":"2023-06-03T10:28:33.350630Z","shell.execute_reply.started":"2023-06-03T10:28:33.340748Z","shell.execute_reply":"2023-06-03T10:28:33.349807Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"discharge_capacities = np.load(r\"/kaggle/input/rul-dhruv/discharge_capacity.npy\", allow_pickle=True)\ndischarge_capacities = discharge_capacities.tolist()","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:33.354190Z","iopub.execute_input":"2023-06-03T10:28:33.356423Z","iopub.status.idle":"2023-06-03T10:28:33.575131Z","shell.execute_reply.started":"2023-06-03T10:28:33.356387Z","shell.execute_reply":"2023-06-03T10:28:33.574035Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(discharge_capacities,percentage,window_size,stride,channels,type):\n\n    train_data =[]\n    FPC_data  =[]\n    name = 0\n    test_data = []\n    FPC_data_dict ={}\n    test_data_dict = {}\n    if(type == \"train\"):\n        \n        for battery in discharge_capacities:\n            a = len(FPC_data)\n#             battery = np.asarray(battery)\n            \n            battery = np.asarray([battery[i] for i in channels])\n            battery_name = 'battery' + str(name)\n            FPC_data_dict[battery_name] =[]\n            name = name+1\n            \n            # Taking inital x% as input and giving the output as 1\n            i= 0\n            target = 1\n            while(i+stride+window_size <= int(percentage*len(battery[0])) and len(battery[0][i:i+window_size]) == window_size):\n                train_data.append((battery[:,i:i+window_size], target,battery_name ))\n                i = i+stride\n\n            # Taking inputs in the middle for FPC\n            i = int(percentage*len(battery[0]))\n            target = -1\n            while(i+stride+window_size <= int((1-percentage)*len(battery[0])) and len(battery[0][i:i+window_size]) == window_size):\n                FPC_data.append((battery[:,i:i+window_size], target,battery_name))\n                FPC_data_dict[battery_name].append(torch.tensor(battery[:,i:i+window_size]).float())\n                i = i+stride\n\n            # Taking last x% as input and giving the output as 0\n            i = int((1-percentage)*len(battery[0]))\n            target = 0\n            while(i+stride <= len(battery[0]) and len(battery[0][i:i+window_size]) == window_size):\n                train_data.append((battery[:,i:i+window_size], target ,battery_name))\n                i = i+stride\n            # print(len(FPC_data)-a, len(battery[0]), len(FPC_data)-a- .90*len(battery[0]))\n\n        return train_data,FPC_data,FPC_data_dict\n\n    else:\n        name = 100\n        for battery in discharge_capacities:\n            \n            battery = np.asarray([battery[i] for i in channels])\n            i= 0\n            battery_name = 'battery' + str(name)\n            test_data_dict[battery_name] =[]\n            name = name+1\n            while(i+stride <= len(battery[0]) and len(battery[0][i:i+window_size]) == window_size):\n                test_data.append((battery[:,i:i+window_size], 1,battery_name))\n                test_data_dict[battery_name].append(torch.tensor(battery[:,i:i+window_size]).float())\n                i = i+stride\n\n        return test_data,test_data_dict\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:33.578037Z","iopub.execute_input":"2023-06-03T10:28:33.578771Z","iopub.status.idle":"2023-06-03T10:28:33.595481Z","shell.execute_reply.started":"2023-06-03T10:28:33.578734Z","shell.execute_reply":"2023-06-03T10:28:33.594407Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class battery_dataloader(Dataset):\n    \n    def __init__(self,data):\n        self.data = data\n    \n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        inp =  torch.tensor(self.data[idx][0]).float()\n        output = torch.tensor(self.data[idx][1]).float()\n        name = self.data[idx][2]\n        return inp, output,name ","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:33.597314Z","iopub.execute_input":"2023-06-03T10:28:33.597959Z","iopub.status.idle":"2023-06-03T10:28:33.610838Z","shell.execute_reply.started":"2023-06-03T10:28:33.597922Z","shell.execute_reply":"2023-06-03T10:28:33.609611Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"percentage  = 0.10  # 10 percent data\nwindow_size = 50    # window size\nstride = 1          # stride\nchannels  =[0,2,3]  # channels\n\n\ntrain_data,FPC_data,FPC_data_dict = get_data(discharge_capacities[:100],percentage,window_size,stride,channels,type = \"train\")\ntest_data,test_data_dict  = get_data(discharge_capacities[100:],None,window_size,stride,channels,type= \"test\")\n\nobj_train  = battery_dataloader(train_data)\nobj_FPC  = battery_dataloader(FPC_data)\nobj_test  = battery_dataloader(test_data)\n\n\ntrain_dataloader = DataLoader(obj_train, batch_size=8,shuffle=True)\nFPC_dataloader   = DataLoader(obj_FPC,batch_size=1,shuffle=False)\ntest_dataloader = DataLoader(obj_test, batch_size=1,shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:33.613109Z","iopub.execute_input":"2023-06-03T10:28:33.613717Z","iopub.status.idle":"2023-06-03T10:28:35.172349Z","shell.execute_reply.started":"2023-06-03T10:28:33.613678Z","shell.execute_reply":"2023-06-03T10:28:35.171351Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(\"Number of Channels  :\", channels)\nprint(\"Shape of a batch    :\",next(iter(train_dataloader))[0].shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:35.173949Z","iopub.execute_input":"2023-06-03T10:28:35.175005Z","iopub.status.idle":"2023-06-03T10:28:35.212132Z","shell.execute_reply.started":"2023-06-03T10:28:35.174952Z","shell.execute_reply":"2023-06-03T10:28:35.210940Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number of Channels  : [0, 2, 3]\nShape of a batch    : torch.Size([8, 3, 50])\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\nclass CNN_Model(nn.Module):\n    \n    def __init__(self,input_size, channels):\n        super(CNN_Model, self).__init__()\n        self.name = \"CNN\"\n        filter_size_1 = 21\n        filter_size=21\n        \n        self.conv1 = nn.Conv1d(channels,16,kernel_size = filter_size_1, stride=1,padding=filter_size_1//2)\n        self.batch_norm1 = nn.BatchNorm1d(16)\n        self.max_pool1 = nn.MaxPool1d(2)\n        \n\n        self.conv2 = nn.Conv1d(16,32, kernel_size = filter_size_1, stride = 1,padding=filter_size_1 //2)\n        self.batch_norm2 = nn.BatchNorm1d(32)\n        self.max_pool2 = nn.MaxPool1d(2)\n\n        self.conv3 = nn.Conv1d(32,64, kernel_size = filter_size, stride = 1,padding=filter_size //2)\n        self.batch_norm3 = nn.BatchNorm1d(64)\n        self.max_pool3 = nn.MaxPool1d(2)\n\n       \n        self.flatten_size = 128*math.floor(input_size/(2*2*2*2))\n        self.flatten = nn.Flatten(start_dim=1)\n        \n        self.Linear1 = nn.Linear(self.flatten_size, input_size)\n        self.batch_norm_linear = nn.BatchNorm1d(input_size)\n        # self.a = nn.Linear()\n        self.Linear2 = nn.Linear(input_size,1)\n        \n        self.relu = nn.ReLU()\n        self.tanh = nn.Tanh()\n        self.gelu = nn.GELU()\n        self.sigmoid = nn.Sigmoid()\n        self.dropout = nn.Dropout(p=0.3)\n        # print(self.flatten_size)\n        \n        \n        \n    def forward(self,x):\n        # x= x.view(x.shape[0],1,x.shape[1])\n        \n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.batch_norm1(out)\n        out = self.dropout(out)\n        out = self.max_pool1(out)\n\n        out = self.conv2(out)\n        out = self.relu(out)\n        out = self.batch_norm2(out)\n        out = self.dropout(out)\n        out = self.max_pool2(out)   \n\n        out = self.conv3(out)\n        out = self.relu(out)\n        out = self.batch_norm3(out)\n        out = self.dropout(out)\n        out = self.max_pool3(out) \n\n        out = self.flatten(out)\n        \n        out = self.Linear1(out)  \n        out = self.Linear2(out)\n\n        out = self.sigmoid(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:35.214060Z","iopub.execute_input":"2023-06-03T10:28:35.214914Z","iopub.status.idle":"2023-06-03T10:28:35.229965Z","shell.execute_reply.started":"2023-06-03T10:28:35.214878Z","shell.execute_reply":"2023-06-03T10:28:35.228786Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\ndef train_model(window_size,channels,train_dataloader,epochs,lr, load_pretrained,path,version):\n    \n    \n\n    \n    model = CNN_Model(window_size,channels)\n    if(load_pretrained):\n        model.load_state_dict(torch.load(path, map_location=device ))\n\n    \n    model.to(device)\n\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr = lr, betas= (0.9, 0.99))\n    criterion = nn.BCELoss()\n    metric = BinaryAccuracy().to(device)\n    early_stopping = EarlyStopping(patience=20)\n\n\n    for epoch in range(epochs):\n        total_loss = 0\n        model.train()\n        model.requires_grad_(True)\n        acc = 0\n        total_loss = 0\n        total = 0\n        total_batches = 0\n        for x, y ,_ in train_dataloader:\n\n            x = x.to(device=device)\n            y = y.to(device=device)\n            out = model(x)\n            acc += metric(out, y.unsqueeze(1))\n\n            loss = criterion(out,y.unsqueeze(1))\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item() * x.size()[0]\n            total += x.size()[0]\n            total_batches +=1\n\n\n        print(\"Loss = {} Accuarcy ={}\".format(total_loss/total,acc/total_batches))\n\n        evaluation = total_loss/total\n        early_stopping(evaluation, model, model_path)\n        \n        if early_stopping.early_stop:\n            print('Early stopping')\n            break\n    model.load_state_dict(torch.load(model_path, map_location=device ))    \n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:35.232021Z","iopub.execute_input":"2023-06-03T10:28:35.232900Z","iopub.status.idle":"2023-06-03T10:28:35.247137Z","shell.execute_reply.started":"2023-06-03T10:28:35.232873Z","shell.execute_reply":"2023-06-03T10:28:35.246071Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\nwindow_size = 50\nlearning_rate = 0.001\n\npretrained = False\nload_pretrained = False\nversion = 1\n\nmodel_dir = \"./Weights/FPC/\"\nmodel_path = f'{model_dir}/model_f{len(channels)}_f{window_size}_f{version}.pth'\n\nif(pretrained):\n    model = CNN_Model(window_size,len(channels))\n    model.load_state_dict(torch.load(model_path, map_location=device ))\n    model.to(device)\nelse:\n    model = train_model(window_size,len(channels),train_dataloader,epochs,learning_rate,load_pretrained,model_path,version)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T10:28:35.248672Z","iopub.execute_input":"2023-06-03T10:28:35.249310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.onnx.export(model, next(iter(train_dataloader))[0], 'iris.onnx', input_names=[\"features\"], output_names=[\"logits\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ind,battery in enumerate([1]):\n    pred1 = []\n    count = 0\n    battery_name = \"battery\"+ str(battery)\n    for x in FPC_data_dict[battery_name]:\n        x = x.view(1,x.shape[0],x.shape[1])\n        x = x.to(device=device)\n\n\n        out = torch.where(model(x) > 0.5, 1, 0) \n        pred1.append(out.cpu().detach().numpy()[0][0].astype(float))\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_fpc_window(pred,patiance):\n    \n    count = 0\n    for window,pred_value in enumerate(pred):\n        if(pred_value.item() ==0):\n            count =  count +1\n        if(pred_value.item() ==1):\n            count =0\n        if(window == len(pred)-1):\n            change_index = window-count\n            return change_index,[1.0 if i<change_index else 0.0 for i in range(len(pred))]\n        if(count == patiance):\n            change_index = window - patiance\n            return change_index,[1.0 if i<change_index else 0.0 for i in range(len(pred))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_fpc(model,batteries,discharge_capacities,data_loader,plot,show_FPC_curve,add_initial,save_path):\n    \n    plt.figure()\n    if(plot):\n        rows = 4\n        col  = 1\n        fig, ax = plt.subplots(rows,col,figsize=(10,6),sharex=True, sharey=True)\n        ax = ax.flatten()\n        plt.suptitle(\"FPC Prediction\", fontsize = 20)\n        # fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n\n    \n    change_percentage = []\n    change_indices    = []\n    model.eval()\n    pred = []\n    \n    \n    for ind,battery in enumerate(batteries):\n#         pred = []\n#         count = 0\n#         for x, y ,_ in data_loader:\n#             x = x.to(device=device)\n#             y = y.to(device=device)\n            \n#             initial_count = count                # This is used to avoid iterating over all batteries in the dataset \n#             if(_[0][7:] == str(battery)):\n#                 out = torch.where(model(x) > 0.5, 1, 0)\n#                 pred.append(out.cpu().detach().numpy()[0][0].astype(float))\n#                 count = count +1\n#             if(initial_count==count and count >1):\n#                 break\n        pred = []\n        count = 0\n        battery_name = \"battery\"+ str(battery)\n        for x in data_loader[battery_name]:\n            x = x.view(1,x.shape[0],x.shape[1])\n            x = x.to(device=device)\n            out = torch.where(model(x) > 0.5, 1, 0) \n            pred.append(out.cpu().detach().numpy()[0][0].astype(float))\n\n        index,smoothed_output = get_fpc_window(pred,patiance=10)   # Index where the the transition occurs\n        index = index*stride\n\n        if(add_initial):\n            change_indices.append(index+int(percentage*len(discharge_capacities[battery][0])))\n        else:\n            change_indices.append(index)\n        \n        change_percentage.append(100*discharge_capacities[battery][0][index]/max(discharge_capacities[battery][0]))\n        \n        if(show_FPC_curve):\n            FPC_curve = np.copy(discharge_capacities[battery][0])\n            FPC_curve[1:int(percentage*len(discharge_capacities[battery][0]))] = None\n            FPC_curve[int((1-percentage)*len(discharge_capacities[battery][0])):-1] = None\n\n            Non_FPC_curve = np.copy(discharge_capacities[battery][0])\n            Non_FPC_curve[int(percentage*len(discharge_capacities[battery][0])):int((1-percentage)*len(discharge_capacities[battery][0]))] = None\n    \n            pred_padded = np.pad(pred, (int(percentage*len(discharge_capacities[battery][0])), 0), constant_values=(np.nan,))\n            smoothed_output_padded = np.pad(smoothed_output, (int(percentage*len(discharge_capacities[battery][0])), 0), constant_values=(np.nan,))\n            \n            if(plot == True):\n                ax[ind].plot(FPC_curve, color = 'orange')\n                ax[ind].plot(Non_FPC_curve, color ='red')\n                ax[ind].plot(pred_padded,color ='blue')\n                ax[ind].plot(smoothed_output_padded,color ='black')\n        \n                ax[ind].legend([\"FPC\", \"NON-FPC\",\"Prediction\",\"Smoothed Output\"])\n                ax[ind].set_title(\"Battery =\" +str(battery+1))\n        else:\n            if(plot):\n                \n                ax[ind].plot(discharge_capacities[battery][0], color = 'orange')\n                ax[ind].plot(pred, color ='red')\n                ax[ind].plot(smoothed_output, color ='black')\n                ax[ind].legend([\"Actual\", \"Prediction\", \"Smoothed Prediction\"])\n                ax[ind].set_title(\"Battery =\" +str(battery+1))\n    \n   \n#     fig.supxlabel('Cycles')\n#     fig.supylabel('Discharge Capacity')\n#     plt.savefig(save_path+\".png\")\n    return change_percentage, change_indices\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batteries = [i for i in range(0,4)]\n_,_ = get_fpc(model,batteries,discharge_capacities,FPC_data_dict,True, True,True,\"FPC_Training\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batteries = [i+100 for i in range(0,4)]\n_,_ = get_fpc(model,batteries,discharge_capacities,test_data_dict,True, False,False,\"FPC_Testing\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_of_channels = [1,2,3,4,5,6,7]\nno_of_channels = [channels]\nchanges_train = []\nchanges_test = []\nepochs = 50\n# os.mkdir(\"/kaggle/working/change_indices\")\nget_saved_indices = False\n\nif(not get_saved_indices):\n\n    for channels in no_of_channels: \n        print(\"Channels used : \", channels)\n        percentage  = 0.10  # 5 percent data\n        window_size = 50    # window size\n        stride = 1          # stride\n\n        train_data,FPC_data,FPC_data_dict = get_data(discharge_capacities[:100],percentage,window_size,stride,channels,type = \"train\")\n        test_data,test_data_dict  = get_data(discharge_capacities[100:],None,window_size,stride,channels,type= \"test\")\n\n        obj_train  = battery_dataloader(train_data)\n        obj_FPC  = battery_dataloader(FPC_data)\n        obj_test  = battery_dataloader(test_data)\n\n        train_dataloader = DataLoader(obj_train, batch_size=8,shuffle=True)\n        FPC_dataloader   = DataLoader(obj_FPC,batch_size=1,shuffle=False)\n        test_dataloader = DataLoader(obj_test, batch_size=1,shuffle=False)\n\n        print(\"Shape of a batch    :\",next(iter(train_dataloader))[0].shape)\n   \n\n        batteries_train =[i for i in range (100)]\n        batteries_test= [i+100 for i in range(0,24)]\n\n        change_percentage_train, change_indices_train =  get_fpc(model,batteries_train,discharge_capacities,FPC_data_dict,False, False,True,\"/kaggle/working/\")\n        change_percentage_test, change_indices_test =  get_fpc(model,batteries_test,discharge_capacities,test_data_dict,False, False,False,\"/kaggle/working/\")\n\n\n        changes_train.append(np.mean(change_percentage_train))\n        changes_test.append(np.mean(change_percentage_test))\n        \n        \n        if(os.path.exists(\"./change_indices\") == False):\n            os.mkdir(\"./change_indices\")\n\n        np.save(f\"./change_indices/change_indices_train_{len(channels)}.npy\",change_indices_train, allow_pickle=True)\n        np.save(f\"./change_indices/change_indices_test_{len(channels)}.npy\",change_indices_test, allow_pickle=True)\n\n        np.save(f\"./change_indices/change_percentage_train_{len(channels)}.npy\",change_percentage_train, allow_pickle=True)\n        np.save(f\"./change_indices/change_percentage_test_{len(channels)}.npy\",change_percentage_test, allow_pickle=True)\n\nelse:\n    print(\"Loading Old Indices\")\n    change_indices_train = np.load(f\"./change_indices/change_indices_train_{len(channels)}.npy\" , allow_pickle=True)\n    change_indices_test = np.load(f\"./change_indices/change_indices_test_{len(channels)}.npy\",allow_pickle=True)\n\n    # change_percentage_train = np.load(\"./change_indices/change_percentage_train.npy\",allow_pickle=True)\n    # change_percentage_test = np.load(\"/change_indices/change_percentage_test.npy\",allow_pickle=True)\n\n    \n\n\n# import pandas as pd\n# results = pd.DataFrame([changes_train,changes_test], columns=no_of_channels, index=[\"Train\",\"Test\"])\n# results.to_csv('channel_analysis.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def NormalizeData(data):\n    return (data - np.min(data)) / (np.max(data) - np.min(data)), (max(data), min(data))\n\n\n\n        \ndef get_data_RUL_scenario1(discharge_capacities,change_indices, window_size,stride,channels, type):\n        \n        if(type == \"Train\"):\n            \n            train_data =[]\n            for index,battery in enumerate(discharge_capacities):\n                    battery = np.asarray([battery[i] for i in channels])\n                    battery_name = \"battery\" + str(index)\n                    i = change_indices[index]   # FPC cycle\n                    \n                    percentage_index = 0\n                    \n                    EOL = len(battery[0])\n\n                    while(i+stride+window_size+1 <= int(len(battery[0])) and len(battery[0][i:i+window_size]) == window_size):\n                            train_data.append((battery[:,i:i+window_size], 1-((i-change_indices[index])/(EOL - change_indices[index])),battery_name ))\n                            i = i+stride\n                            percentage_index = percentage_index+1\n\n            return train_data\n        else:\n            print(type)\n            test_data =[]\n            for index,battery in enumerate(discharge_capacities):\n                    battery = np.asarray([battery[i] for i in channels])\n                    battery_name = \"battery\" + str(index+100)\n                    i = change_indices[index]   # FPC cycle\n                    percentage_index = 0\n                    \n                    EOL = len(battery[0])\n                    \n\n                    while(i+stride+window_size+1 <= int(len(battery[0])) and len(battery[0][i:i+window_size]) == window_size):\n                            test_data.append((battery[:,i:i+window_size], 1-(i-change_indices[index])/(EOL - change_indices[index]),battery_name ))\n                            i = i+stride\n                            percentage_index = percentage_index+1\n                        \n            return test_data\n\ndef get_data_RUL_scenario2(discharge_capacities,change_indices, window_size,stride,channels, type):\n        \n        if(type == \"Train\"):\n            \n            train_data =[]\n            for index,battery in enumerate(discharge_capacities):\n                    battery = np.asarray([battery[i] for i in channels])\n                    battery_name = \"battery\" + str(index)\n                    i = change_indices[index]\n                    \n                    percentage_index = 0\n                    normalized_capacity,_ = NormalizeData(battery[0][i:])\n\n                    while(i+stride+window_size+1 <= int(len(battery[0])) and len(battery[0][i:i+window_size]) == window_size):\n                            train_data.append((battery[:,i:i+window_size], normalized_capacity[percentage_index],battery_name ))\n                            i = i+stride\n                            percentage_index = percentage_index+1\n\n            return train_data\n        else:\n            print(type)\n            test_data =[]\n            for index,battery in enumerate(discharge_capacities):\n                    battery = np.asarray([battery[i] for i in channels])\n                    battery_name = \"battery\" + str(index+100)\n                    i = change_indices[index]\n                    percentage_index = 0\n                    normalized_capacity,_ = NormalizeData(battery[0][i:])\n\n                    while(i+stride+window_size+1 <= int(len(battery[0])) and len(battery[0][i:i+window_size]) == window_size):\n                            test_data.append((battery[:,i:i+window_size], normalized_capacity[percentage_index],battery_name ))\n                            i = i+stride\n                            percentage_index = percentage_index+1\n            return test_data\n            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nclass CNN_Model_RUL(nn.Module):\n    \n    def __init__(self,input_size, channels):\n        super(CNN_Model_RUL, self).__init__()\n        self.name = \"CNN\"\n        filter_size_1 = 21\n        filter_size   = 21\n        \n        self.conv1 = nn.Conv1d(channels,16,kernel_size = filter_size_1, stride=1,padding=filter_size_1//2)\n        self.batch_norm1 = nn.BatchNorm1d(16)\n        self.max_pool1 = nn.MaxPool1d(2)\n        \n\n        self.conv2 = nn.Conv1d(16,32, kernel_size = filter_size_1, stride = 1,padding=filter_size_1 //2)\n        self.batch_norm2 = nn.BatchNorm1d(32)\n        self.max_pool2 = nn.MaxPool1d(2)\n\n        self.conv3 = nn.Conv1d(32,64, kernel_size = filter_size, stride = 1,padding=filter_size //2)\n        self.batch_norm3 = nn.BatchNorm1d(64)\n        self.max_pool3 = nn.MaxPool1d(2)\n\n       \n        self.flatten_size = 128*math.floor(input_size/(2*2*2*2))\n        self.flatten = nn.Flatten(start_dim=1)\n        \n        self.Linear1 = nn.Linear(self.flatten_size, input_size)\n        self.batch_norm_linear = nn.BatchNorm1d(input_size)\n        # self.a = nn.Linear()\n        self.Linear2 = nn.Linear(input_size,1)\n        \n        self.relu = nn.ReLU()\n        self.tanh = nn.Tanh()\n        self.gelu = nn.GELU()\n        self.sigmoid = nn.Sigmoid()\n        self.dropout = nn.Dropout(p=0.1)\n        # print(self.flatten_size)\n        \n        \n        \n    def forward(self,x):\n        # x= x.view(x.shape[0],1,x.shape[1])\n        \n        out = self.conv1(x)\n        # out = self.relu(out)\n        out = self.batch_norm1(out)\n        out = self.dropout(out)\n        out = self.max_pool1(out)\n\n        out = self.conv2(out)\n        # out = self.relu(out)\n        out = self.batch_norm2(out)\n        out = self.dropout(out)\n        out = self.max_pool2(out)   \n\n        # out = self.conv3(out)\n        # out = self.relu(out)\n        # out = self.batch_norm3(out)\n        # out = self.dropout(out)\n        # out = self.max_pool3(out) \n\n        out = self.flatten(out)\n        \n        out = self.Linear1(out)  \n        out = self.Linear2(out)\n#         out = self.sigmoid(out)\n\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTM_Model_RUL(nn.Module):\n    \n    def __init__(self,input_size,channels):\n        super(LSTM_Model_RUL, self).__init__()\n        self.name = \"LSTM\"\n        hidden_size1 = input_size\n        hidden_size2 = input_size\n        \n        num_layers = 4\n        self.LSTM1 = nn.LSTM(input_size = input_size, hidden_size = hidden_size1, num_layers = num_layers,batch_first=True)\n        self.LSTM2 = nn.LSTM(input_size = input_size, hidden_size = hidden_size2, num_layers = num_layers,batch_first=True)\n\n        self.flatten = nn.Flatten()\n        self.Linear1 = nn.Linear(hidden_size2*channels,128)\n        self.Linear2 = nn.Linear(128,1)\n        self.Linear3 = nn.Linear(50,1)\n        self.relu    = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self,x):\n        \n        # self.h0 = torch.randn(4, x.size(0), 100)\n        # self.c0 = torch.randn(4, x.size(0), 100)\n        \n        # x= x.view(x.shape[0],channels,x.shape[1])\n        # out, (hn, cn) = self.LSTM(x, (self.h0, self.c0))\n\n        out, (_, _) = self.LSTM1(x)\n        out,(_,_) = self.LSTM2(out)\n        \n        out = self.flatten(out)\n        out = self.relu(out)\n        out = self.Linear1(out)\n        out = self.relu(out)\n        out = self.Linear2(out)\n#         out = self.relu(out)\n#         out = self.Linear3(out)\n#         out = self.sigmoid(out)\n\n\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class battery_dataloader_RUL(Dataset):\n    \n    def __init__(self,data):\n        self.data = data\n    \n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        inp =  torch.tensor(self.data[idx][0]).float()\n        output = torch.tensor(self.data[idx][1]).float()\n        battery_name = self.data[idx][2]\n        \n        return inp, output, battery_name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channels = [0,2,3,4,]\nwindow_size = 50\nstride =1\n\ntrain_data_RUL_scenario1= get_data_RUL_scenario1(discharge_capacities[:100],change_indices_train,window_size,stride,channels,\"Train\")\nobj_train_RUL_scenario1  = battery_dataloader_RUL(train_data_RUL_scenario1)\n\ntest_data_RUL_scenario1= get_data_RUL_scenario1(discharge_capacities[100:],change_indices_test,window_size,stride,channels,\"Test\")\nobj_test_RUL_scenario1  = battery_dataloader_RUL(test_data_RUL_scenario1)\n\n\ntrain_data_RUL_scenario2= get_data_RUL_scenario2(discharge_capacities[:100],change_indices_train,window_size,stride,channels,\"Train\")\nobj_train_RUL_scenario2  = battery_dataloader_RUL(train_data_RUL_scenario2)\n\ntest_data_RUL_scenario2= get_data_RUL_scenario2(discharge_capacities[100:],change_indices_test,window_size,stride,channels,\"Test\")\nobj_test_RUL_scenario2  = battery_dataloader_RUL(test_data_RUL_scenario2)\n\n\n\n\ntrain_dataloader_RUL_scenario1 = DataLoader(obj_train_RUL_scenario1, batch_size=128,shuffle=True)\ntrain_dataloader_RUL_temp_scenario1 = DataLoader(obj_train_RUL_scenario1, batch_size=1,shuffle=False)\ntest_dataloader_RUL_scenario1 = DataLoader(obj_test_RUL_scenario1, batch_size=1,shuffle=False)\n\ntrain_dataloader_RUL_scenario2 = DataLoader(obj_train_RUL_scenario2, batch_size=128,shuffle=True)\ntrain_dataloader_RUL_temp_scenario2 = DataLoader(obj_train_RUL_scenario2, batch_size=1,shuffle=False)\ntest_dataloader_RUL_scenario2 = DataLoader(obj_test_RUL_scenario2, batch_size=1,shuffle=False)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchmetrics.classification import BinaryAccuracy\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\ndef train_model_RUL(window_size,channels,train_dataloader,epochs,lr,load_pretrained,path,version):\n    \n    model_RUL = LSTM_Model_RUL(window_size,channels)\n    if(load_pretrained):\n        print(\"Loading a Pre-trained Model\")\n        model_RUL.load_state_dict(torch.load(path,map_location= device))\n    else:\n        print(\"Training a new model\")\n    model_RUL.to(device) \n        \n    optimizer = torch.optim.Adam(model_RUL.parameters(), lr = lr, betas= (0.9, 0.99))\n    criterion = nn.L1Loss()\n             \n    model_RUL.train()\n    \n    early_stopping = EarlyStopping(patience=30)\n\n    for epoch in range(epochs):\n        total_loss = 0\n        \n        model_RUL.requires_grad_(True)\n        acc = 0\n        total_loss = 0\n        total = 0\n        total_batches = 0\n        for x, y ,_ in train_dataloader:\n\n            x = x.to(device=device)\n            y = y.to(device=device)\n            out = model_RUL(x)\n\n            loss = criterion(out,y.unsqueeze(1))\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item() * x.size()[0]\n            total += x.size()[0]\n            total_batches +=1\n\n\n        print(\"Epoch = {}, Loss = {} \".format(epoch, total_loss/total))\n        \n        evaluation = total_loss/total\n        early_stopping(evaluation, model_RUL,path)\n        if early_stopping.early_stop:\n            print('Early stopping')\n            break\n    model_RUL.load_state_dict(torch.load(path, map_location=device ))  \n    return model_RUL\n            \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.00001\nepochs = 200\npretrained_RUL_scenario1 = False\npretrained_RUL_scenario2 = False\n\nmodel_dir_scenario1 = \"./Weights/Scenario1/\"\nmodel_path_scenario1 = f'{model_dir_scenario1}/model_f{len(channels)}_f{window_size}_f{version}.pth'\n\nmodel_dir_scenario2 = \"./Weights/Scenario2/\"\nmodel_path_scenario2 = f'{model_dir_scenario2}/model_f{len(channels)}_f{window_size}_f{version}.pth'\n\n\nversion = 1\n\n\nif(pretrained_RUL_scenario1):\n    model_RUL_scenario1 = LSTM_Model_RUL(window_size,len(channels))\n    model_RUL_scenario1.load_state_dict(torch.load(model_path_scenario1,map_location= device))\n    model_RUL_scenario1.to(device)  \n\nelse:\n    load_pretrained_scenario1 = False\n    model_RUL_scenario1 = train_model_RUL(window_size, len(channels),train_dataloader_RUL_scenario1,epochs,learning_rate,load_pretrained_scenario1,model_path_scenario1,version) \n\n# if(pretrained_RUL_scenario2):\n#     model_RUL_scenario2 = LSTM_Model_RUL(window_size,len(channels))\n#     model_RUL_scenario2.load_state_dict(torch.load(model_path_scenario2,map_location= device))\n#     model_RUL_scenario2.to(device)  \n# else:\n#     load_pretrained_scenario2 = False\n#     model_RUL_scenario2 = train_model_RUL(window_size, len(channels),train_dataloader_RUL_scenario2,epochs,learning_rate,load_pretrained_scenario2,model_path_scenario2,version) \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchmetrics import MeanAbsolutePercentageError\n\ndef plot_RUL(model,discharge_capacities,batteries,data_loader,change_indices,save_path):\n\n    rows = 1\n    col  = len(batteries)\n    fig, ax = plt.subplots(col,rows,figsize=(12,2*len(batteries)))\n    ax = ax.flatten()\n    plt.suptitle(\"Results\", fontsize = 20)\n    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n\n    mse_loss = 0\n    mae_loss =0 \n    mape_loss =0 \n    for ind,battery in enumerate(batteries):\n        pred = []\n        count = 0\n        actual = []\n        for x, y ,_ in data_loader:\n            x = x.to(device)\n            y = y.to(device)\n\n            initial_count = count\n\n            if(_[0][7:] == str(battery)):\n                out = model(x)\n                pred.append(out.cpu().detach().numpy()[0][0].astype(float))\n                actual.append(y.cpu().detach().numpy()[0].astype(float))\n                count = count +1\n            if(initial_count==count and count >1):\n                break\n        \n        if(battery>=100):\n            change_indices_battery = battery - 100\n        else:\n            change_indices_battery = battery\n\n        l = nn.MSELoss()\n        l1 = nn.L1Loss()\n        l2 = MeanAbsolutePercentageError()\n        if(len(pred)!=0):\n            mse_loss += l(torch.Tensor(pred),torch.Tensor(actual))\n            mae_loss += l1(torch.Tensor(pred),torch.Tensor(actual))\n            mape_loss += l2(torch.Tensor(pred),torch.Tensor(actual))\n        \n        x = [change_indices[change_indices_battery]+i for i in range(len(pred))]\n        # print(len(discharge_capacities[battery][0]))\n        ax[ind].plot(x,pred)\n        ax[ind].plot(x,actual)\n        \n        ax[ind].legend(['Predicted', 'Actual'])\n        ax[ind].set_title(\"Battery\"+str(battery))\n\n    print(\"MSE= {}, MAE ={} , MAPE = {}\".format(mse_loss/len(batteries),mae_loss/len(batteries),mape_loss/len(batteries)))\n    \n    plt.savefig(save_path+\".png\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batteries =[0,1,2]\n# plot_RUL(model_RUL_scenario2,discharge_capacities,batteries,train_dataloader_RUL_temp_scenario2,change_indices_train,\"scenario2_RUL_prediction_train\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_batteries  = [i+100 for i in [16,17,18]]\n# plot_RUL(model_RUL_scenario2,discharge_capacities,test_batteries,test_dataloader_RUL_scenario2,change_indices_test,\"scenario2_RUL_prediction_test\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batteries  = [i+100 for i in range(24)]\nplot_RUL(model_RUL_scenario1,discharge_capacities,test_batteries,test_dataloader_RUL_scenario1,change_indices_test,\"scenario1_RUL_prediction_test\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batteries =[0,1,2,3]\n# plot_RUL(model_RUL_scenario1,discharge_capacities,batteries,train_dataloader_RUL_temp_scenario1,change_indices_train,\"scenario1_RUL_prediction_train\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}