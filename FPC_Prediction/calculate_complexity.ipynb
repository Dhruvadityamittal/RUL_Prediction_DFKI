{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmittal/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "import torch\n",
    "from pthflops import count_ops\n",
    "from model import CNN_Model, LSTM_Model_RUL, CNN_Model_RUL, Net, Net_new, Autoencoder, LSTM_Model, TransformerLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 64\n",
    "channels = 7\n",
    "model_RUL_LSTM = LSTM_Model_RUL(window_size,channels)  # LSTM Model\n",
    "# model_RUL = Net(len(channels_RUL))    # Transformer Model\n",
    "model_RUL_CNN = CNN_Model_RUL(window_size,channels)    # CNN Model\n",
    "model_RUL_TransformerLSTM = TransformerLSTM(channels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1,7,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation OPS     \n",
      "--------  ------  \n",
      "relu      896     \n",
      "linear1   57472   \n",
      "relu_1    256     \n",
      "linear2   129     \n",
      "-------   -----   \n",
      "Input size: (1, 7, 64)\n",
      "58,753 FLOPs or approx. 0.00 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model_RUL_LSTM_Flops = count_ops(model_RUL_LSTM, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation   OPS      \n",
      "----------  -------  \n",
      "conv1       151552   \n",
      "relu        2048     \n",
      "max_pool1   512      \n",
      "conv2       345088   \n",
      "relu_1      2048     \n",
      "max_pool2   512      \n",
      "linear1     32832    \n",
      "linear2     65       \n",
      "---------   ------   \n",
      "Input size: (1, 7, 64)\n",
      "534,657 FLOPs or approx. 0.00 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model_RUL_CNN_Flops = count_ops(model_RUL_CNN, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Proxy' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_RUL_TransformerLSTM_Flops \u001b[39m=\u001b[39m count_ops(model_RUL_TransformerLSTM, \u001b[39minput\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/pthflops/__init__.py:14\u001b[0m, in \u001b[0;36mcount_ops\u001b[0;34m(model, input, mode, custom_ops, ignore_layers, print_readable, verbose, *args)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount_ops\u001b[39m(model, \u001b[39minput\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfx\u001b[39m\u001b[39m'\u001b[39m, custom_ops\u001b[39m=\u001b[39m{}, ignore_layers\u001b[39m=\u001b[39m[], print_readable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mfx\u001b[39m\u001b[39m'\u001b[39m \u001b[39m==\u001b[39m mode \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m force_jit:\n\u001b[0;32m---> 14\u001b[0m         \u001b[39mreturn\u001b[39;00m count_ops_fx(\n\u001b[1;32m     15\u001b[0m             model,\n\u001b[1;32m     16\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m             custom_ops\u001b[39m=\u001b[39;49mcustom_ops,\n\u001b[1;32m     18\u001b[0m             ignore_layers\u001b[39m=\u001b[39;49mignore_layers,\n\u001b[1;32m     19\u001b[0m             print_readable\u001b[39m=\u001b[39;49mprint_readable,\n\u001b[1;32m     20\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     21\u001b[0m             \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     22\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mjit\u001b[39m\u001b[39m'\u001b[39m \u001b[39m==\u001b[39m mode \u001b[39mor\u001b[39;00m force_jit:\n\u001b[1;32m     23\u001b[0m         \u001b[39mif\u001b[39;00m force_jit:\n",
      "File \u001b[0;32m~/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/pthflops/ops_fx.py:254\u001b[0m, in \u001b[0;36mcount_ops_fx\u001b[0;34m(model, input, custom_ops, ignore_layers, print_readable, verbose, *args)\u001b[0m\n\u001b[1;32m    251\u001b[0m model_status \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtraining\n\u001b[1;32m    252\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 254\u001b[0m tracer \u001b[39m=\u001b[39m ProfilingInterpreter(model, custom_ops\u001b[39m=\u001b[39;49mcustom_ops)\n\u001b[1;32m    255\u001b[0m tracer\u001b[39m.\u001b[39mrun(\u001b[39minput\u001b[39m)\n\u001b[1;32m    257\u001b[0m ops \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/pthflops/ops_fx.py:183\u001b[0m, in \u001b[0;36mProfilingInterpreter.__init__\u001b[0;34m(self, mod, custom_ops)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, mod: torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, custom_ops: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m {}):\n\u001b[0;32m--> 183\u001b[0m     gm \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfx\u001b[39m.\u001b[39;49msymbolic_trace(mod)\n\u001b[1;32m    184\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(gm)\n\u001b[1;32m    186\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcustom_ops \u001b[39m=\u001b[39m custom_ops\n",
      "File \u001b[0;32m~/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:1070\u001b[0m, in \u001b[0;36msymbolic_trace\u001b[0;34m(root, concrete_args)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[39mSymbolic tracing API\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[39m    GraphModule: a Module created from the recorded operations from ``root``.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m tracer \u001b[39m=\u001b[39m Tracer()\n\u001b[0;32m-> 1070\u001b[0m graph \u001b[39m=\u001b[39m tracer\u001b[39m.\u001b[39;49mtrace(root, concrete_args)\n\u001b[1;32m   1071\u001b[0m name \u001b[39m=\u001b[39m (\n\u001b[1;32m   1072\u001b[0m     root\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(root, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule) \u001b[39melse\u001b[39;00m root\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m   1073\u001b[0m )\n\u001b[1;32m   1074\u001b[0m \u001b[39mreturn\u001b[39;00m GraphModule(tracer\u001b[39m.\u001b[39mroot, graph, name)\n",
      "File \u001b[0;32m~/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:739\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autowrap_search:\n\u001b[1;32m    733\u001b[0m             _autowrap_check(\n\u001b[1;32m    734\u001b[0m                 patcher, module\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    735\u001b[0m             )\n\u001b[1;32m    736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_node(\n\u001b[1;32m    737\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    738\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m--> 739\u001b[0m             (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_arg(fn(\u001b[39m*\u001b[39;49margs)),),\n\u001b[1;32m    740\u001b[0m             {},\n\u001b[1;32m    741\u001b[0m             type_expr\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__annotations__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    742\u001b[0m         )\n\u001b[1;32m    744\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubmodule_paths \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/RUL_Prediction_DFKI/FPC_Prediction/model.py:456\u001b[0m, in \u001b[0;36mTransformerLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    453\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpermute(x, (\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m) )\n\u001b[1;32m    455\u001b[0m \u001b[39m# B, 1, L, C -> B, n_classes\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m    458\u001b[0m \u001b[39m# BCE loss\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:717\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[39mreturn\u001b[39;00m _orig_module_call(mod, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    712\u001b[0m _autowrap_check(\n\u001b[1;32m    713\u001b[0m     patcher,\n\u001b[1;32m    714\u001b[0m     \u001b[39mgetattr\u001b[39m(\u001b[39mgetattr\u001b[39m(mod, \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m, mod), \u001b[39m\"\u001b[39m\u001b[39m__globals__\u001b[39m\u001b[39m\"\u001b[39m, {}),\n\u001b[1;32m    715\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autowrap_function_ids,\n\u001b[1;32m    716\u001b[0m )\n\u001b[0;32m--> 717\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_module(mod, forward, args, kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:434\u001b[0m, in \u001b[0;36mTracer.call_module\u001b[0;34m(self, m, forward, args, kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m module_qualified_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_of_module(m)\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_leaf_module(m, module_qualified_name):\n\u001b[0;32m--> 434\u001b[0m     \u001b[39mreturn\u001b[39;00m forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    435\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_proxy(\u001b[39m\"\u001b[39m\u001b[39mcall_module\u001b[39m\u001b[39m\"\u001b[39m, module_qualified_name, args, kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:710\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 710\u001b[0m     \u001b[39mreturn\u001b[39;00m _orig_module_call(mod, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/RUL_Prediction/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/RUL_Prediction_DFKI/FPC_Prediction/TinyHAR.py:588\u001b[0m, in \u001b[0;36mTinyHAR_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[39m# ------->  B x C x L* x F*       \u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39m\"\"\" =============== cross channel interaction ===============\"\"\"\u001b[39;00m\n\u001b[1;32m    587\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[0;32m--> 588\u001b[0m     [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel_interaction(x[:, :, t, :])\u001b[39m.\u001b[39munsqueeze(\u001b[39m3\u001b[39m) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(x\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m])],\n\u001b[1;32m    589\u001b[0m     dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    590\u001b[0m )\n\u001b[1;32m    591\u001b[0m \u001b[39m# ------->  B x C x F* x L* \u001b[39;00m\n\u001b[1;32m    593\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Proxy' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "model_RUL_TransformerLSTM_Flops = count_ops(model_RUL_TransformerLSTM, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "Flops = 1200869.0 Parameters = 27861.0\n"
     ]
    }
   ],
   "source": [
    "macs, pars = profile(model_RUL_TransformerLSTM, inputs = (input,))\n",
    "print(\"Flops = {}, Parameters = {}\". format(macs,pars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "Flops = 1003648.0 Parameters = 190721.0\n"
     ]
    }
   ],
   "source": [
    "macs, pars = profile(model_RUL_LSTM, inputs = (input,))\n",
    "print(\"Flops = {}, Parameters = {}\". format(macs,pars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Flops = 527424.0 Parameters = 46049.0\n"
     ]
    }
   ],
   "source": [
    "macs, pars = profile(model_RUL_CNN, inputs = (input,))\n",
    "print(\"Flops = {}, Parameters = {}\". format(macs,pars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RUL_Prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
